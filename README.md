Periodontal Ligament Segmentation using U-Net

Overview

This project focuses on segmenting the periodontal ligament (PDL) using U-Net.

Dataset
	â€¢	The dataset consists of 100 high-resolution PDF images (~7000Ã—4000), where dental specialists manually marked the periodontal ligament regions using a red pen on a tablet.
	â€¢	Challenges:
	â€¢	The large image size makes processing difficult.
	â€¢	The manual annotations may be imprecise, affecting segmentation accuracy.

Preprocessing (preprocess.ipynb)

This script extracts the input images and segmentation masks from PDF files.

Steps:
	1.	Convert to Grayscale & Remove Borders
	â€¢	Convert RGB to Grayscale:

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)


	â€¢	Detect and remove black borders using contours.

	2.	Extract Red Annotations (PDL Regions) Using HSV Color Space
	â€¢	Convert RGB to HSV:

hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


	â€¢	Define HSV ranges to detect red markings:

lower_red1 = np.array([0, 120, 70])  # Low-saturation red  
upper_red1 = np.array([10, 255, 255])  
lower_red2 = np.array([170, 120, 70])  # High-saturation red  
upper_red2 = np.array([180, 255, 255])  


	3.	Fill the Segmentation Mask
	â€¢	The provided annotations only outline the PDL region, so the interior must be filled.
	â€¢	Contour Filling:

contours, _ = cv2.findContours(filled_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)


	â€¢	Handling Disconnected Annotations:
	â€¢	Fill small gaps (â‰¤ 5Ã—5 pixels).
	â€¢	Downscale the image, detect contours, and upscale again to minimize information loss.
	â€¢	Iteratively increase the filling size from 5Ã—5 to 100Ã—100 for optimal results.

Model & Training (unet.ipynb)

Preprocessing:
	â€¢	Convert to grayscale and apply standard scaling:

normalized_image = (image - mean) / std



Challenges in Applying U-Net to Large Images
	1.	U-Net requires square images with power-of-2 dimensions (e.g., 256Ã—256, 512Ã—512).
	2.	Directly loading the full images in a DataLoader causes memory overflow.

Solutions:

âœ… Crop and Pad: Center-crop the image and pad it into a square shape.
âœ… Resize: Reduce image size while preserving key features.
âœ… Sliding Window Approach (Chosen Method):
	â€¢	Divide the image into 1024Ã—1024 patches, ensuring that each patch contains meaningful segmentation regions.

Training:
	â€¢	Batch Size: 1
	â€¢	Architecture: Standard U-Net (no modifications to depth or layers).
	â€¢	Initial Result:
	â€¢	The model predicts only black images (no segmentation).
	â€¢	Likely due to a severe class imbalance â†’ Most patches contain only background (0s), with few containing the periodontal ligament.

Addressing Class Imbalance

Strategies to Improve Segmentation Performance:
	1.	Hard Negative Mining:
	â€¢	Increase sampling frequency of patches containing periodontal ligament (e.g., train on PDL patches 3Ã— more often than background patches).
	2.	Focal Loss:
	â€¢	Use Focal Loss instead of Cross Entropy to focus training on difficult cases.
	3.	ROI-Based Segmentation (Region Proposal + Segmentation):
	â€¢	Step 1: Use Faster R-CNN or YOLO to detect the periodontal ligament region.
	â€¢	Step 2: Apply U-Net only on detected regions to improve efficiency.
	4.	Semi-Supervised Learning:
	â€¢	Leverage unlabeled data using self-training or consistency regularization techniques.

Conclusion & Next Steps

This project tackles large-scale medical image segmentation by:
	â€¢	Developing a robust preprocessing pipeline for extracting high-quality segmentation masks.
	â€¢	Addressing image size limitations using patch-based training.
	â€¢	Proposing class imbalance handling techniques to improve U-Netâ€™s segmentation performance.

ðŸ”¹ Next Steps: Experiment with Hard Negative Mining, Focal Loss, and ROI-based segmentation to enhance results. ðŸš€
